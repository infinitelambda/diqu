var __index = {"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"What is it?","text":""},{"location":"index.html#diqu","title":"diqu","text":"<p>Automate and streamline the alerting/ notification process for dbt test results using this versatile CLI companion tool. Receive detailed alerts &amp; test metadata seamlessly on various platforms, promoting improved collaboration on dbt project issues \ud83d\udc1e\ud83d\ude80.</p>"},{"location":"index.html#who-is-this-for","title":"Who is this for","text":"<p>This tool is designed for individuals or teams seeking to automate the management of their dbt project issues (test warnings, errors... etc) outside the dbt environment.</p>"},{"location":"index.html#features","title":"Features","text":"<ul> <li>Automated alerts and notifications based on recorded dbt test results.</li> <li>Built-in support for dq-tools and custom query input.</li> <li>Auto-labels <code>deprecated</code> tests for quick &amp; easy identification.</li> <li>Sends succinct and informative messages to a dedicated Slack channel.</li> <li>Creates and updates Jira tickets with the latest tests' metadata.</li> </ul>"},{"location":"index.html#supported-modules","title":"Supported Modules","text":"<ul> <li>Sources (DWH connections)<ul> <li>Snowflake</li> <li>CSV file</li> </ul> </li> <li>Package (parsing dbt test results)<ul> <li></li> <li>Custom query</li> </ul> </li> <li>Alert Modules (alert/ notification)<ul> <li>Jira</li> <li>Slack</li> </ul> </li> </ul>"},{"location":"index.html#concept","title":"Concept \u2b50","text":"<p>dbt alert rant \ud83d\udfe2 \ud83d\udfe1 \ud83d\udd34 \u26ab - by <code>diqu</code> OG Contributors</p> <p>Run errors are red,</p> <p>Test warnings are yellow,</p> <p>Where's my bug alert,</p> <p>And joint bugfix workflow?</p> <p> </p> <p>We made a cool thing called <code>diqu</code> (pronounced 'deekoo'), a CLI tool to make bugfix lives a lil bit easier. Its goal is simple: streamlining collaboration and enhancing agility in our daily (if not hourly) bugfix with dbt.</p> <p>Let's face it, the dbt result log is not built for alerting or team bugfix collaboration. Firstly, test warnings exist only in dbt's log, there's no way to get alerted on new warnings every day (or worse, every hour, depending on your ETL schedules) unless you open the log. Secondly, scrolling through a thousand-line log with the whole team to decide who gonna do what is, well, not a smart idea. <code>diqu</code> solves these by simply shipping all the test warnings/ errors, along with their metadata (e.g. latest failure, previous statuses ...) to other platforms (e.g. Slack, Jira) that support better alerting &amp; collaborations.</p> <p><code>diqu</code> reads your test results table (provided by dbt packages that parse result log, such as ), transform it into simple yet insightful bug metadata, and send it to your output of choices. The output platforms are modularized, which enables contributors to improve &amp; add more modules if needed.</p>"},{"location":"index.html#basic-usage","title":"Basic Usage","text":"<pre><code>diqu alert --to slack --to jira\n</code></pre> <pre><code>04:33:17  diqu: INFO - Run with diqu==1.0.0 \ud83c\udfc3\n04:33:19  diqu: INFO - Using dbt project at: /path/to/dbt/project\n04:33:19  diqu: INFO - Using dbt profiles.yml at: ~/.dbt\n04:33:19  diqu: INFO - Using snowflake connection\n04:33:19  diqu: INFO - Looking for the query in: ./query.sql\n04:33:23  diqu: INFO - Alerting to: SLACK\n04:33:23  diqu: INFO - \u2705 Done &gt; Slack\n04:33:23  diqu: INFO - Alerting to: JIRA\n04:33:23  diqu: INFO - \u2705 Done &gt; JIRA\n</code></pre> <p>\ud83d\udcd6 For more details, please jump to the User Guide page or the Quick Start page.</p>"},{"location":"index.html#how-to-contribute","title":"How to Contribute","text":"<p>This Auto Alert (<code>diqu</code>) tool is an open-source software. Whether you are a seasoned open-source contributor or a first-time committer, we welcome and encourage you to contribute code, documentation, ideas, or problem statements to this project.</p> <p>\ud83d\udc49 See CONTRIBUTING guideline for more details</p> <p>\ud83c\udf1f And then, kudos to our beloved Contributors:</p> <p> </p>"},{"location":"index.html#about-infinite-lambda","title":"About Infinite Lambda","text":"<p>Infinite Lambda is a cloud and data consultancy. We build strategies, help organisations implement them and pass on the expertise to look after the infrastructure.</p> <p>We are an Elite Snowflake Partner, a Platinum dbt Partner and two-times Fivetran Innovation Partner of the Year for EMEA.</p> <p>Naturally, we love exploring innovative solutions and sharing knowledge, so go ahead and:</p> <p>\ud83d\udd27 Take a look around our Git</p> <p>\u270f\ufe0f Browse our tech blog</p> <p>We are also chatty, so:</p> <p>\ud83d\udc40 Follow us on LinkedIn</p> <p>\ud83d\udc4b\ud83c\udffc Or just get in touch</p> <p></p>"},{"location":"nav/dev/contributing.html","title":"Contributing to <code>diqu</code>","text":"<p><code>diqu</code> is open-source software. Whether you are a seasoned open-source contributor or a first-time committer, we welcome and encourage you to contribute code, documentation, ideas, or problem statements to this project.</p> <ul> <li>Contributing to <code>diqu</code></li> <li>About this document</li> <li>Getting the code<ul> <li>Installing git</li> <li>External contributors</li> </ul> </li> <li>Setting up your dev environment<ul> <li>Tools</li> </ul> </li> <li>Testing<ul> <li><code>pytest</code></li> </ul> </li> <li>Submitting a Pull Request</li> </ul>"},{"location":"nav/dev/contributing.html#about-this-document","title":"About this document","text":"<p>There are many ways to contribute to the ongoing development of <code>diqu</code>, such as by participating in discussions and issues.</p> <p>The rest of this document serves as a more granular guide for contributing code changes to <code>diqu</code> (this repository). It is not intended as a guide for using <code>diqu</code>, and some pieces assume a level of familiarity with Python development with <code>poetry</code>. Specific code snippets in this guide assume you are using macOS or Linux and are comfortable with the command line.</p> <ul> <li>Branches: All pull requests from community contributors should target the <code>main</code> branch (default). If the change is needed as a patch for a minor version of dbt that has already been released (or is already a release candidate), a maintainer will backport the changes in your PR to the relevant \"latest\" release branch (<code>1.0.&lt;latest&gt;</code>, <code>1.1.&lt;latest&gt;</code>, ...). If an issue fix applies to a release branch, that fix should be first committed to the development branch and then to the release branch (rarely release-branch fixes may not apply to <code>main</code>).</li> <li>Releases: Before releasing a new minor version, we prepare a series of beta release candidates to allow users to test the new version in live environments. This is an important quality assurance step, as it exposes the new code to a wide variety of complicated deployments and can surface bugs before the official release. Releases are accessible via <code>pip</code>.</li> </ul>"},{"location":"nav/dev/contributing.html#getting-the-code","title":"Getting the code","text":""},{"location":"nav/dev/contributing.html#installing-git","title":"Installing git","text":"<p>You will need <code>git</code> to download and modify the <code>diqu</code> source code. On macOS, the best way to download git is to just install Xcode.</p>"},{"location":"nav/dev/contributing.html#external-contributors","title":"External contributors","text":"<p>You can contribute to <code>diqu</code> by forking the <code>diqu</code> repository. For a detailed overview on forking, check out the GitHub docs. In short, you will need to:</p> <ol> <li>Fork the <code>diqu</code> repository</li> <li>Clone your fork locally</li> <li>Check out a new branch for your proposed changes</li> <li>Push changes to your fork</li> <li>Open a pull request against <code>infintelambda/diqu</code> from your forked repository</li> </ol>"},{"location":"nav/dev/contributing.html#setting-up-your-dev-environment","title":"Setting up your dev environment","text":"<p>Here are some helpful tools for local development. While this list is tailored for <code>diqu</code> development, many of these tools are used commonly across open-source Python projects.</p>"},{"location":"nav/dev/contributing.html#tools","title":"Tools","text":"<p>We will use <code>poetry</code> in <code>diqu</code> development and testing.</p> <p>So first install poetry via pip or via the official installer:</p> <pre><code>python3 -m pip install poetry --upgrade\n</code></pre> <p>Then, start installing the local environment:</p> <pre><code>python3 -m poetry install\npython3 -m poetry shell\npoe git-hooks\npip install -e .\ndiqu -h\n</code></pre>"},{"location":"nav/dev/contributing.html#testing","title":"Testing","text":"<p>Once you're able to test manually &amp; your code change is working as expected, it's important to run existing automated tests, as well as add some new ones. These tests will ensure the following:</p> <ul> <li>Your code changes do not unexpectedly break other established functionality</li> <li>Your code changes can handle all known edge cases</li> <li>The functionality you're adding will keep working in the future</li> </ul>"},{"location":"nav/dev/contributing.html#pytest","title":"<code>pytest</code>","text":"<p>Finally, you can also run a specific test or group of tests using <code>pytest</code>. With a virtualenv active and dev dependencies installed, you can do the following:</p> <pre><code>poe test\n</code></pre> <p>Run tests with coverage report:</p> <pre><code>poe test-cov\n</code></pre> <p>See pytest usage docs for an overview of useful command-line options.</p>"},{"location":"nav/dev/contributing.html#submitting-a-pull-request","title":"Submitting a Pull Request","text":"<p>Code can be merged into the current development branch <code>main</code> by opening a pull request. A <code>diqu</code> maintainer will review your PR. They may suggest code revision for style or clarity, or request that you add unit or integration test(s). These are good things! We believe that, with a little bit of help, anyone can contribute high-quality code.</p> <p>Automated tests run via GitHub Actions. If you're a first-time contributor, all tests (including code checks and unit tests) will require a maintainer to approve. Changes in the <code>diqu</code> repository trigger integration tests against Postgres. dbt Labs also provides CI environments in which to test changes to other adapters, triggered by PRs in those adapters' repositories, as well as periodic maintenance checks of each adapter in concert with the latest <code>diqu</code> code changes.</p> <p>Once all tests are passed and your PR has been approved, a <code>diqu</code> maintainer will merge your changes into the active development branch. And that's it! Happy developing </p>"},{"location":"nav/guide/cli.html","title":"CLI Reference","text":""},{"location":"nav/guide/cli.html#cli-reference-diqu","title":"CLI Reference (diqu)","text":"<p>Run <code>diqu --help</code> or <code>diqu -h</code> to see the basic guideline for CLI Reference</p> diqu -h Usage: diqu [OPTIONS] COMMAND [ARGS]...   CLI companion tool to support dq-tools package and more  Options: --version Show the version and exit. --help, -h Show this message and exit.  Commands: alert Alert the issues   Specify one of these sub-commands and you can find more help from there."},{"location":"nav/guide/cli.html#diqu-alert","title":"diqu alert","text":"<p>Alert the issues to JIRA Board</p> <p>Examples:</p> CLI (within dbt project)CLI (outside of dbt project) <pre><code>diqu alert\n</code></pre> <pre><code>diqu alert --project-dir /path/to/dbt\n</code></pre>"},{"location":"nav/guide/cli.html#send-alerts-to-other-channels","title":"Send alerts to other channels","text":"Use <code>--to</code> option <pre><code>diqu alert --to &lt;your channel module&gt;\n</code></pre> <p>Current supported channels could be found in <code>(repo)/diqu/alerts/</code>:</p> <ul> <li>JIRA: default</li> <li>Slack: <code>diqu alert --to slack</code></li> </ul>"},{"location":"nav/guide/cli.html#customize-the-alerts-query","title":"Customize the alert's query","text":"Use <code>--query-dir</code> and <code>--query-file</code> option <pre><code>diqu alert \\\n  --query-dir /path/to/dir \\\n  --query-file myquery.sql\n</code></pre> <p>For example, you'd have a query built in <code>myquery.sql</code> file which is located at the root of your dbt project dir e.g. <code>/opt/alert/mydbt/</code>, your command should look like:</p> <pre><code>```bash\ndiqu alert --query-dir /opt/alert/mydbt --query-file myquery.sql\n```\n</code></pre>"},{"location":"nav/guide/cli.html#use-a-specific-dbt-profile-instead-of-pointing-to-the-dbt-project","title":"Use a specific dbt profile instead of pointing to the dbt project","text":"Use <code>--profile-name</code> option <pre><code>diqu alert --profile-name &lt;my_profile&gt;\n</code></pre> <p>For example, the <code>dbt_project.yml</code> is as below:</p> <pre><code>name: 'my_awesome_dbt'\nversion: '1.0.0'\nconfig-version: 2\n\nprofile: 'my_awesome_dbt_profile' # this is the profile name\n...\n</code></pre> <p>And, the <code>profiles.yml</code> content is:</p> <pre><code>my_awesome_dbt_profile:\n    target: snowflake\n    outputs:\n    snowflake:\n        type: snowflake\n        account: \"{{ env_var('DBT_SNOWFLAKE_TEST_ACCOUNT') }}\"\n        user: \"{{ env_var('DBT_SNOWFLAKE_TEST_USER') }}\"\n        password: \"{{ env_var('DBT_ENV_SECRET_SNOWFLAKE_TEST_PASSWORD') }}\"\n        role: \"{{ env_var('DBT_SNOWFLAKE_TEST_ROLE') }}\"\n        database: \"{{ env_var('DBT_SNOWFLAKE_TEST_DATABASE') }}\"\n        warehouse: \"{{ env_var('DBT_SNOWFLAKE_TEST_WAREHOUSE') }}\"\n        schema: \"{{ env_var('DBT_SCHEMA') }}\"\n        threads: 10\n\nmy_other_dbt_profile:\n    target: snowflake\n    ...\n</code></pre> <p>Finally, the command is: <code>diqu alert --profile-name my_awesome_dbt_profile</code> which can be run anywhere (inside or outside of the dbt project dir).</p>"},{"location":"nav/guide/cli.html#configure-the-sql-context-in-case-that-your-tableview-is-on-a-different-schema-or-database-configured-in-the-dbt-profile","title":"Configure the SQL context in case that your table/view is on a different schema or database configured in the dbt profile","text":"Use <code>--query-database</code> and <code>--query-schema</code> option <pre><code>diqu alert --query-database &lt;db&gt; --query-schema &lt;schema&gt;\n</code></pre> <p>Additionally, in the query file dq_tools__get_test_results.sql, you need to have a configuration to specify the main table/view which is:     <pre><code>with\n\nsource as (\n  select * from $database.$schema.dq_issue_log\n),\n...\n</code></pre></p> <ul> <li><code>--query-database</code> value will replace <code>$database</code> placeholder</li> <li><code>--query-schema</code> value will replace <code>$schema</code> placeholder</li> </ul>"},{"location":"nav/guide/common.html","title":"User Guide","text":""},{"location":"nav/guide/common.html#modules","title":"Modules","text":"<p><code>diqu</code> CLI is built in the modular approach with 3 main ones:</p> <ol> <li>Source Modules: Build Data Source connections (e.g. Snowflake, csv file)</li> <li>Package Modules: Manage the Query of the issues captured (e.g. <code>dq-tools</code>'s query)</li> <li>Alert Modules: Define how to alert/notify the issue to which platforms (e.g. Jira, Slack)</li> </ol> <p>\ud83d\udc49 See the next pages for more information on how to configure the modules</p>"},{"location":"nav/guide/common.html#how-it-works","title":"How it works","text":"<p>Generally, <code>diqu</code> executes the following steps:</p> <ol> <li> <p>Takes in dbt test results from your Source Module of choice, let refer to this as the <code>test_results</code> table.</p> <ul> <li>Depending on the Package Module you are using, the schema of this table might vary.</li> <li>If you are using CSV as the Source Module, the schema of <code>test_results</code> should be defined by the <code>.csv</code>.</li> </ul> </li> <li> <p>A Query specified for this <code>test_results</code>'s schema is executed to produce the common <code>test metadata</code> for Alert Module</p> </li> <li>The Alert Module of choice takes the <code>test metadata</code> in the previous steps and sends it to the specified destinations</li> </ol>"},{"location":"nav/guide/common.html#issue-statuses-issue-deprecation","title":"Issue Statuses &amp; Issue Deprecation","text":"<p>Besides the basic dbt test statuses (<code>pass</code>, <code>warn</code>, <code>error</code>), in the built-in query for <code>dq-tools</code>, we introduced the new status of <code>deprecate</code>.</p> <p><code>deprecate</code> means no longer valid, and we don't need to take immediate action (erm ... hooray \ud83d\ude4c?).</p> <p>A test is marked <code>deprecate</code> if it's not executed &amp; recorded in a specified number of days.</p> <p>This can defined by the <code>ISSUE_DEPRECATED_WINDOW_IN_DAYS</code> variable (see Query Variables Config)</p> <p>Our built-in query also labels each status with its corresponding \"traffic lights\" \ud83d\udea5 icon for easier identification (who doesn't love colorful icons in their alerts? \ud83c\udf89)</p> <ul> <li><code>pass</code>(\ud83d\udfe2)</li> <li><code>warn</code>(\ud83d\udfe1)</li> <li><code>failed</code>(\ud83d\udd34)</li> <li><code>deprecate</code>(\u26ab)</li> </ul> <p>The statuses of each executed dbt test are crucial for issue management, hence it is highly recommended to include in your custom CSV or custom Query if you're building one yourself.</p>"},{"location":"nav/guide/quick_start.html","title":"Quick Start","text":""},{"location":"nav/guide/quick_start.html#quick-start-diqu","title":"Quick Start (<code>diqu</code>)","text":"<p>This introduction assumes you are already using dbt (and the dq-tools package) in your project, and have the log table ready.</p> <p>To get started using <code>diqu</code>, we'll go over the steps required &amp; explain what possibilities this package creates for you.</p>"},{"location":"nav/guide/quick_start.html#1-installation","title":"1. Installation","text":"pip install diqu --upgrade Successfully installed diqu restart \u21bb <p>\ud83d\udcd3 NOTE: The required Data Warehouse (DWH) module should already be installed if you are using <code>diqu</code> in a working dbt project. If not, please perform additional steps to install these DWH modules.</p> <p>For example, if you're using Snowflake:</p> <pre><code>pip install \"snowflake-connector-python[pandas]\"\npip install \"snowflake-connector-python[secure-local-storage]\"\n</code></pre>"},{"location":"nav/guide/quick_start.html#2-profile-setup","title":"2. Profile setup","text":"<p>We're trying to reuse the dbt <code>profiles.yml</code>'s format regardless to whether you use dbt or not in order to configure the DWH connection, in this case, the Snowflake connection.</p> <p>The content of the file should be like this:</p> <pre><code>diqu_demo:\n  outputs:\n    dev:\n      type: snowflake\n      account: &lt;your_value&gt;\n      role: &lt;your_value&gt;\n\n      user: &lt;your_value&gt;\n      password: &lt;your_value&gt;\n\n      warehouse: &lt;your_value&gt;\n      database: &lt;your_value&gt;\n      schema: &lt;your_value&gt;\n      threads: &lt;your_value&gt;\n\n  target: dev\n</code></pre> <p>See more details in here.</p> <p>Or, for just the csv file as the connection:</p> <pre><code>diqu_demo:\n  outputs:\n    dev:\n      type: csv\n      dir: ./.cache\n\n  target: dev\n</code></pre> <p>In this case, we need to download data into <code>csv__data.csv</code> file and put it under <code>.cache</code> directory. See how the file is schema-ed here.</p>"},{"location":"nav/guide/quick_start.html#3-usage","title":"3. Usage","text":"<p>Optionally, try to configure the preflight's rules or skip &amp; leave it as default:</p> <pre><code># define the query params:\n# - your_issue_deprecation_time_in_day, default to \"3\"\nexport ISSUE_DEPRECATED_WINDOW_IN_DAYS=?\n# - your_issue_historical_data_update_window_in_days, default to \"14\"\nexport ISSUE_UPDATE_WINDOW_IN_DAYS=?\n\n# build dq-tools log table:\ndbt run -s dq_tools\n</code></pre> <p>And then, run the Alerting:</p> <pre><code>diqu alert --to slack --to jira\n</code></pre> <p>Here is the sample logs:</p> <pre><code>04:33:17  diqu: INFO - Run with diqu==1.0.0 \ud83c\udfc3\n04:33:19  diqu: INFO - Using dbt project at: /path/to/dbt/project\n04:33:19  diqu: INFO - Using dbt profiles.yml at: ~/.dbt\n04:33:19  diqu: INFO - Using snowflake connection\n04:33:19  diqu: INFO - Looking for the query in: ./query.sql\n04:33:23  diqu: INFO - Alerting to: SLACK\n04:33:23  diqu: INFO - \u2705 Done &gt; Slack\n04:33:23  diqu: INFO - Alerting to: JIRA\n04:33:23  diqu: INFO - \u2705 Done &gt; JIRA\n</code></pre> <p>Before we can run the Alerting, surely we need to configure the Alert credentials:</p>"},{"location":"nav/guide/quick_start.html#slack-channel","title":"Slack Channel","text":"<p>Use the environment variables to configure the Slack Channel:</p> <pre><code>export SLACK_TOKEN=your_token\nexport SLACK_CHANNEL=your_channel_name\n</code></pre> <p>Then, go alert:</p> <pre><code>diqu alert --to slack\n</code></pre>"},{"location":"nav/guide/quick_start.html#jira-board","title":"Jira Board","text":"<p>Use the environment variables to configure the JIRA Board:</p> <pre><code>export JIRA_SERVER=your_jira_server e.g. https://your_value.atlassian.net/\nexport JIRA_AUTH_USER=your_service_account e.g. dqt_user@your_value.com\nexport JIRA_AUTH_PASSWORD=your_service_token e.g. ATATTxxxxx\nexport JIRA_PROJECT_ID=your_project_id e.g. 106413\nexport JIRA_ISSUE_TYPE=your_issue_type, default to \"Bug\"\nexport JIRA_OPEN_ISSUES_FILTER_BY_SUMMARY=your_issue_filter_on_title, default to \"dq-tools\"\n</code></pre> <p>Then, go alert:</p> <pre><code>diqu alert --to jira\n</code></pre> <p>\ud83d\udcd6 For more details, please jump to the User Guide page.</p>"},{"location":"nav/guide/quick_start.html#quick-demo","title":"Quick Demo","text":""},{"location":"nav/guide/adapters/community_adapter.html","title":"Contribute to adapters \u2764\ufe0f","text":""},{"location":"nav/guide/adapters/community_adapter.html#contribute-to-adapters","title":"Contribute to adapters","text":"<p>Community adapters are plugins contributed and maintained by members of the diqu community. We welcome and encourage contributions to existing adapters or the creation of new adapters (<code>diqu-{new-adapter}</code>). Keep in mind that community maintainers are volunteers, so please be kind, understanding, and offer help where possible!</p>"},{"location":"nav/guide/adapters/community_adapter.html#contribute-to-the-existing-adapters","title":"Contribute to the existing adapters","text":"<p>Anyone can contribute by testing and writing code. If you're interested, check out the open issues in the plugin's source repository. Use the relevant GitHub repo links below:</p> <ul> <li> <p> Core (<code>diqu</code>)</p> <p>Automate and streamline the alerting / notification process for dbt test results using this versatile CLI companion tool. Receive detailed alerts &amp; test metadata seamlessly on various platforms, promoting improved collaboration on dbt project issues \ud83d\udc1e\ud83d\ude80.</p> <p> infinitelambda/diqu</p> <p> License</p> </li> <li> <p> (Sample only) Email (<code>diqu-email</code>)</p> <p>diqu Adapter: Email</p> <p> datnguye/diqu-email</p> </li> </ul> <p>Don't see your adapter lising here\u2753 Please help to open a PR to add your plugin to this documentation.</p>"},{"location":"nav/guide/adapters/community_adapter.html#create-a-new-adapter","title":"Create a new adapter","text":"<p>If you see something missing from the lists above, and you're interested in developing an integration, here are the basic guideline on how an adapter is developed in the Build, test, document, and promote adapters:</p>"},{"location":"nav/guide/adapters/community_adapter.html#1-introduction","title":"1. Introduction","text":"<p>Since this package is built with the modular approach, the adapters are essential component of <code>diqu</code>.</p> <p>All projects are not the same:</p> <ul> <li>[Package] How do we capture the test result logs or any other similar data? We use <code>dq-tools</code> but it doesn't enforce everyone to follow the same in order to use <code>diqu</code></li> <li>[Source] Which database are we using in the project? We built Snowflake and CSV connection but you will want it to support Big Query for example</li> <li>[Alert] Ways to alert the Incidents/Anomalies: to JIRA or to Azure DevOps? to Slack or to Email? What should be the content of the alert?</li> </ul>"},{"location":"nav/guide/adapters/community_adapter.html#2-prerequisites","title":"2. Prerequisites","text":"<p>It is very important that you have the right skills, and understand the level of difficulty required to make an adapter for your Auto Alert.</p> <p>Maintaining your adapter:</p> <p>When your adapter becomes more popular, and people start using it, you may quickly become the maintainer of an increasingly popular open source project. With this new role, comes some unexpected responsibilities that not only include code maintenance, but also working with a community of users and contributors. To help people understand what to expect of your project, you should communicate your intentions early and often in your adapter documentation or README. Answer questions like, Is this experimental work that people should use at their own risk? Or is this production-grade code that you're committed to maintaining into the future</p> <p>Following <code>diqu</code> vesioning and keeping compatibility:</p> <p>We're highly recomended to follow the Semantic Version convention. New major or minor version of <code>diqu</code> might have the breaking changes which will be clearly communicating through the Release Notes, it is important to put it on the radar and make the changes accordingly to adapt it to your adapter.</p> <p>We also encourage that your adapter's version should follow the Core's minor version to avoid any future confusion of usage, for example, <code>diqu</code> v1.0.x then your adapter <code>diqu-email</code> will version as v1.0.x</p>"},{"location":"nav/guide/adapters/community_adapter.html#3-build-a-new-adapter","title":"3. Build a new adapter","text":"<p>This step will walk you through the first creating the necessary adapter classes and functions, and provide some resources to help you validate that your new adapter is working correctly. Make sure you've familiarized yourself with the previous steps in this guide.</p> <p>In the meantime, we don't have the <code>cookiecutter</code> template to help you to quickly generate the project from a scaffold.</p> <p>Here is the project skeleton for your new adapter, for example, <code>diqu-new-adapter</code>:</p>"},{"location":"nav/guide/adapters/community_adapter.html#providing-extensions-for-the-alert-module-only","title":"Providing extensions for the <code>alert</code> module only","text":"<pre><code>(repo)\n  | - diqu\n  |  | - alerts\n  |  | - alerts/__init__.py\n  |  | - alerts/&lt;new_module&gt;.py\n  | - diqu/__init__.py\n</code></pre> <p>In your <code>alerts/&lt;new_module&gt;.py</code>:</p> <pre><code>from diqu.utils.log import logger\nfrom diqu.utils.meta import ResultCode\n\n\ndef alert(data) -&gt; ResultCode:\n    # your implementation here\n    # log any necessary messages e.g. logger.info(\"\u2705 Done &gt; My Module\")\n    # return the ResultCode value\n</code></pre> <p>And your diqu command will be: <code>diqu alert --to &lt;new_module&gt;</code></p>"},{"location":"nav/guide/adapters/community_adapter.html#providing-extensions-for-the-package-module-only","title":"Providing extensions for the <code>package</code> module only","text":"<pre><code>(repo)\n  | - diqu\n  |  | - packages\n  |  | - packages/__init__.py\n  |  | - packages/&lt;new_module&gt;.py\n  | - diqu/__init__.py\n</code></pre> <p>In your <code>packages/&lt;new_module&gt;.py</code>:</p> <pre><code>from diqu.utils.log import logger\n\ndef get_query(config: dict) -&gt; str:\n    # your implementation here, return the SQL query\n</code></pre> <p>And your diqu command will be: <code>diqu alert --package &lt;new_module&gt;</code></p>"},{"location":"nav/guide/adapters/community_adapter.html#providing-extensions-for-the-source-module-only","title":"Providing extensions for the <code>source</code> module only","text":"<pre><code>(repo)\n  | - diqu\n  |  | - sources\n  |  | - sources/__init__.py\n  |  | - sources/&lt;new_module&gt;.py\n  | - diqu/__init__.py\n</code></pre> <p>In your <code>sources/&lt;new_module&gt;.py</code>:</p> <pre><code>from diqu.utils.log import logger\nfrom diqu.sources.base import BaseConnection\n\n\ndef get_connection(config: dict) -&gt; BaseConnection:\n    # your implementation here, return the BaseConnection class\n</code></pre> <p>And your diqu command won't be change, but you should make sure the value of <code>&lt;new_module&gt;</code> will be exact-match to the dbt profiles' <code>type</code> attribute.</p>"},{"location":"nav/guide/adapters/community_adapter.html#combinations-of-above-will-also-doable-and-in-general-here-is-the-whole-project-as-sample","title":"\ud83d\udca1 Combinations of above will also doable. And in general, here is the whole project as sample:","text":"<pre><code>(repo)\n  | - diqu\n  |  | - &lt;module&gt;\n  |  | - &lt;module&gt;/__init__.py\n  |  | - &lt;module&gt;/&lt;new_module&gt;.py\n  | - diqu/__init__.py\n  | - tests/\n  | - LICENSE\n  | - pyproject.toml\n  | - CONTRIBUTING.md\n  | - README.md\n</code></pre> <p>In <code>pyproject.toml</code> file, the content should be as following template:</p> Click me <pre><code>[tool.poetry]\nname = \"diqu-&lt;new-adapter&gt;\"\nversion = \"0.0.0\"\ndescription = \"Data Quality CLI for the Auto-Alerts - &lt;New Adapter&gt;\"\nauthors = [\"Your Name &lt;your_email@domain.com&gt;\"]\nreadme = \"README.md\"\nlicense = \"&lt;YOUR LICENCE&gt;\"\nrepository = \"https://&lt;your-repo-url&gt;\"\nhomepage = \"https://&lt;your-website-url&gt;\"\nkeywords = [\"packaging\", \"poetry\", \"data-quality\", \"alert\", \"notification\", \"collaboration\", \"agility\", \"flake8\", \"markdown\", \"lint\"]\nclassifiers = [\n    \"Environment :: Console\",\n    \"Operating System :: OS Independent\",\n    \"Topic :: Software Development :: Documentation\",\n    \"Topic :: Software Development :: Libraries :: Python Modules\",\n    \"Topic :: Software Development :: Quality Assurance\",\n]\npackages = [\n  {include = \"diqu\"},\n  {include = \"README.md\"},\n]\n\n[tool.poetry.dependencies]\npython = \"&gt;=3.9,&lt;3.13\"\ndiqu = \"&gt;=0.1,&lt;0.2\"\n\n[tool.poetry.dev-dependencies]\npre-commit = \"^2.17.0\"\npoethepoet = \"^0.16.4\"\nblack = \"^23.7.0\"\nflake8 = \"^6.0.0\"\nisort = \"^5.12.0\"\nautoflake = \"^2.0.1\"\npytest = \"^7.2.0\"\npytest-sugar = \"^0.9.6\"\ncoverage = {version = \"^6.5.0\", extras = [\"toml\"]}\n\n[build-system]\nrequires = [\"poetry-core&gt;=1.0.0\"]\nbuild-backend = \"poetry.core.masonry.api\"\n\n[tool.isort]\nmulti_line_output = 3\nforce_to_top = [\"os\"]\nprofile = \"black\"\nskip_gitignore = true\n\n[tool.autoflake]\nrecursive = true\nin-place = true\nremove-all-unused-imports = true\nignore-init-module-imports = true\nremove-unused-variables = true\nignore-pass-statements = false\n\n[tool.coverage.run]\nomit = [\"tests/*\"]\n\n[tool.poe.tasks]\ngit-hooks = { shell = \"pre-commit install --install-hooks &amp;&amp; pre-commit install --hook-type commit-msg\" }\nformat = [\n  {cmd = \"autoflake .\"},\n  {cmd = \"black .\"},\n  {cmd = \"isort .\"},\n]\nlint = [\n  {cmd = \"black --check .\"},\n  {cmd = \"isort --check-only .\"},\n  {cmd = \"flake8 .\"},\n]\ntest = [\n  {cmd = \"pytest .\"},\n]\ntest-cov = [\n  {cmd = \"pytest --version\"},\n  {cmd = \"coverage run -m pytest .\"},\n  {cmd = \"coverage report --show-missing\"},\n  {cmd = \"coverage xml\"},\n]\n</code></pre>"},{"location":"nav/guide/adapters/community_adapter.html#4-test-your-adapter","title":"4. Test your adapter","text":"<ul> <li>Your adapter should be compatible with diqu coresponding minor version</li> <li>You should be familiar with pytest: https://docs.pytest.org/</li> </ul> <p>Let's add your testing under <code>tests/</code> directory to ensure your new modules working as expected. We will encourage your testing would cover 100% coverage if possible \ud83d\ude80.</p>"},{"location":"nav/guide/adapters/community_adapter.html#5-publish-the-new-adapter","title":"5. Publish the new adapter","text":"<p>Many community members maintain their adapter plugins under open source licenses. If you're interested in doing this, we recommend:</p> <ul> <li>Hosting on a public git provider (for example, GitHub or Gitlab)</li> <li>Publishing to PyPI</li> <li>Open a PR to this page under Contribute to the existing adapters section</li> </ul> <p>Happy Coding \ud83d\ude80</p>"},{"location":"nav/guide/adapters/using_custom_module_script.html","title":"Using custom module script \ud83d\udca1","text":""},{"location":"nav/guide/adapters/using_custom_module_script.html#using-custom-module-script","title":"Using custom module script","text":"<p>In case you're NOT ready for publishing the adapters (<code>diqu-{new-adapter}</code>), or would like to keep yours privately, it's also supported here.</p> <p>This is a basic guideline to let you do that:</p>"},{"location":"nav/guide/adapters/using_custom_module_script.html#understand-the-module-paths","title":"Understand the module paths","text":"<p>Check out the our supported modules, and here is our skeleton:</p> <pre><code>diqu/\n\u251c\u2500\u2500 diqu/\n    \u251c\u2500\u2500 alerts/     # Alert module\n    \u251c\u2500\u2500 packages/   # Package module\n    \u251c\u2500\u2500 sources/    # Source module\n</code></pre> <p>Let's say that we want to create an alert custom script, named <code>your_alert_module.py</code>. Now, we must follow the above directory structure and put the script under <code>(your_repo)/diqu/alerts/</code> as below:</p> <pre><code>your_repo/\n\u251c\u2500\u2500 diqu/\n    \u251c\u2500\u2500 alerts/\n        \u251c\u2500\u2500 your_alert_module.py # custom script here\n\u251c\u2500\u2500 your_other_dir/\n</code></pre> <p>Follow the same fashion for the <code>Package</code> or <code>Source</code> module \ud83d\udc4d</p>"},{"location":"nav/guide/adapters/using_custom_module_script.html#create-your-module-script","title":"Create your module script","text":"<p>Check out the Build a new adapter for more details on how to structure your code.</p> <p>For example: <code>(your_repo)/diqu/alerts/your_alert_module.py</code></p> <pre><code>from diqu.utils.log import logger\nfrom diqu.utils.meta import ResultCode\n\n\ndef alert(data) -&gt; ResultCode:\n    # your implementation here\n    # log any necessary messages e.g. logger.info(\"\u2705 Done &gt; My Module\")\n    return ResultCode.SUCCEEDED # return the ResultCode value\n</code></pre>"},{"location":"nav/guide/adapters/using_custom_module_script.html#3-run-diqu-with-the-custom-module-script","title":"3. Run <code>diqu</code> with the custom module script","text":"<p>Run <code>diqu alert -h</code> to inspect the usage for using custom:</p> <ul> <li>Alert via <code>--to</code> option (docs)</li> <li>Package via <code>--package</code> option (docs)</li> <li>Source via <code>--profile-name</code> and <code>--profiles-dir</code>  (docs)</li> </ul> <p>For example: <code>(your_repo)/diqu/alerts/your_alert_module.py</code></p> <pre><code>diqu alert --to your_alert_module\n</code></pre> <p>Happy Customizing \ud83d\ude80</p>"},{"location":"nav/guide/config/usage_stats.html","title":"Anonymous usage stats","text":"<p>We aim to enhance the functionality of <code>diqu</code> by gaining insights into user interactions. As part of this effort, we have implemented straightforward event tracking within diqu, utilizing Snowplow.</p> <p>It is important to note that we do not collect credentials or any other type of private info, as we consider this information outside the scope of our interest.</p> <p>The potential uses for usage statistics encompass package maintenance &amp; future module development.</p> <p>By default, event tracking is enabled. However, users of <code>diqu</code> can choose to opt out of this feature at any time by setting the following environment variable</p> <pre><code>export DO_NOT_TRACK=true\n</code></pre>"},{"location":"nav/guide/config/alerts/jira.html","title":"JIRA Config","text":""},{"location":"nav/guide/config/alerts/jira.html#configuration-for-jira-module","title":"Configuration for Jira module","text":"<p>This module creates new Jira issues and/or updates current issues based on your input test results.</p>"},{"location":"nav/guide/config/alerts/jira.html#jira-project-requirements","title":"Jira Project requirements","text":"<p>Besides basic credentials such as <code>JIRA_SERVER</code>, <code>JIRA_AUTH_USER</code>, <code>JIRA_AUTH_PASSWORD</code> and <code>JIRA_PROJECT_ID</code> as specified in the next section, your Jira Project will also need the following:</p> <ul> <li>A dedicated issue type for our tool, defined by <code>JIRA_ISSUE_TYPE</code>, defaults to \"Bug\" \ud83d\udc1b.</li> <li>This issue type must have its <code>Labels</code> field enabled.</li> <li>Only 1 <code>Done</code> status under the <code>Done</code> status category. We are using <code>Done</code> as a filter for open issues, so something like <code>Archived</code> under <code>Done</code> category would mess up the update logic.</li> <li>A dedicated <code>JIRA_OPEN_ISSUES_FILTER_BY_SUMMARY</code>. This is the issue summary suffix to identify issues that we should manage using the module with other issues from the same Jira project. Defaults to \"dq-tools\"</li> </ul>"},{"location":"nav/guide/config/alerts/jira.html#jira-module-config-variables-cli-commands","title":"Jira module config variables &amp; CLI commands","text":"Field Description <code>JIRA_SERVER</code> Your Jira server (e.g., <code>https://your_value.atlassian.net/</code>) <code>JIRA_AUTH_USER</code> Your Jira service account (e.g., <code>user@your_value.com</code>) <code>JIRA_AUTH_PASSWORD</code> Your Jira service token (e.g., <code>ATATTxxxxx</code>) <code>JIRA_PROJECT_ID</code> Your Jira project ID (e.g., <code>123456</code>) <code>JIRA_ISSUE_TYPE</code> Your Jira issue type (default to \"Bug\") <code>JIRA_OPEN_ISSUES_FILTER_BY_SUMMARY</code> Your Jira filter on issue title (default to \"dq-tools\") <p>All Jira configs are currently environment variables, you can set them up using the sample code below:</p> <pre><code>export JIRA_SERVER=https://your_value.atlassian.net/\nexport JIRA_AUTH_USER=dqt_user@your_value.com\nexport JIRA_AUTH_PASSWORD=ATATTxxxxx\nexport JIRA_PROJECT_ID=123456\nexport JIRA_ISSUE_TYPE=Bug\nexport JIRA_OPEN_ISSUES_FILTER_BY_SUMMARY=dq-tools\n</code></pre> <p>To trigger Jira's actions (create and/or update issues), use the following:</p> <pre><code>diqu alert --to jira\n</code></pre>"},{"location":"nav/guide/config/alerts/jira.html#issue-summary-title","title":"Issue summary (title)","text":"<p>The issue's summary (aka issue's title) consists of the following parts:</p> <p>Status of the latest execution + test_id(hash) + issue filter</p> <p>Example: <code>\ud83d\udfe1 | Warning in test: accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8 [dq-tools]</code></p> <p>Note that dbt singular tests don't have a hash suffix, only test names. Hence, if we change the content of a singular test, their test IDs stay the same and the following statuses will still be updated in the same Jira issue. On the other hand, generic test IDs change if we modify their contents, so the module will in turn create a new issue instead.</p>"},{"location":"nav/guide/config/alerts/jira.html#the-relationship-between-jira-issue-and-the-dbt-test","title":"The relationship between Jira issue and the DBT test","text":"<p>A Jira issue (aka a Jira ticket - defined by <code>issue_key</code>) corresponding to 01 dbt test (defined by <code>test_id</code>).</p> <p>Even though there might be multiple executions of 1 test in our test_results table, all of these executions' metadata are displayed in the same Jira issue if the issue is still in the <code>open</code> state (issue' status != <code>Done</code>)</p> <p>In the case where our <code>test_id</code> latest status is not <code>pass</code>, and the previous corresponding issue has been marked <code>Done</code>, the module will create a new issue instead of updating the previous one.</p> <p>In short:</p> <ul> <li>A new issue is created when:<ul> <li>Latest test status != <code>pass</code></li> <li>There is no corresponding <code>issue_key</code>, or the previous <code>issue_key</code> has been marked <code>Done</code></li> </ul> </li> <li>A current issue is updated when:<ul> <li>There is a corresponding <code>issue_key</code> that is not marked <code>Done</code></li> </ul> </li> </ul>"},{"location":"nav/guide/config/alerts/jira.html#automatically-mark-a-jira-issue-as-done","title":"Automatically mark a Jira Issue as <code>Done</code> \u2705","text":"<p>Even though it seems very straightforward, we don't automate the process of marking issues as Done as soon as there's a <code>pass</code> status.</p> <p>The reason is the fluctuations in some test results. We have experienced cases where tests passed and failed randomly in each ETL run, which makes the <code>Done</code> status for those issues incorrect (our tool might create a new issue in the next run).</p> <p>Therefore, until there's a unified approach to this problem, marking Done each Jira issue should be done manually after a thorough assessment of previous statuses.</p>"},{"location":"nav/guide/config/alerts/jira.html#test-metadata-in-jira-issue","title":"Test metadata in Jira issue","text":"<p>Below is the list of test metadata displayed in a Jira issue, and the corresponding issue's component [ <code>Summary</code>, <code>Description</code>, <code>Labels</code> ]  that they are in:</p> <ul> <li>Test metadata:<ul> <li>Test ID [ <code>Summary</code> &amp; <code>Description</code> ] </li> <li>Test tags [ <code>Labels</code> ]</li> </ul> </li> <li>Latest execution metadata [ <code>Description</code> ]<ul> <li>Latest Status: warn</li> <li>Latest Run Timestamp</li> <li>Latest Run Failed Rate</li> </ul> </li> <li>Arrays of previous executions' metadata [ <code>Description</code> ]<ul> <li>Previous statuses</li> <li>Previous run timestamps (UTC)</li> <li>Previous # of failed records</li> <li>Previous # of scanned records</li> </ul> </li> </ul>"},{"location":"nav/guide/config/alerts/jira.html#issue-description-sample","title":"Issue description sample","text":"<p>A sample issue description is as follows:</p> <pre><code>\u2022 Test ID: \u2014 MY_FIRST_DBT_MODEL|id|||test.diqu_dev.accepted_values_my_first_dbt_model_id_False1_2.ee252c12b8 \u2014\n\u2022 Latest Status: warn\n\u2022 Latest Run Timestamp: 2023-11-14 09:29:42.456000 (UTC)\n\u2022 Latest Run Failed Rate: 0.25\n\u2022 Previous statuses: [\"\ud83d\udfe2\", \"\ud83d\udfe2\", \"\ud83d\udfe1\", \"\ud83d\udfe1\", \"\ud83d\udfe1\"]\n\u2022 Previous run timestamps (UTC): [ \"2023-11-07 11:04:10.762\", \"2023-11-07 10:58:31.607\", \"2023-11-07 10:52:53.111\", \"2023-11-07 10:51:24.584\", \"2023-11-07 10:15:31.166\"]\n\u2022 Previous # of failed records: [ 1, 1, 1, 1, 1]\n\u2022 Previous # of scanned records: [ 4, 4, 4, 4, 4]\n\u2022 tag 1: accepted values\n\u2022 tag 2: Accuracy\n\nManaged by diqu | modified at 2023-11-14 09:31:58.832864 (UTC)\n</code></pre> <p>And the example of JIRA issues:</p> <p> </p>"},{"location":"nav/guide/config/alerts/slack.html","title":"Configuration for Slack module","text":"<p>This module creates and sends a short report on the latest dbt test results to a specific Slack channel via a Slack bot</p>"},{"location":"nav/guide/config/alerts/slack.html#slack-requirements","title":"Slack requirements","text":"<ul> <li>A dedicated channel for this module messages</li> <li>A dedicated Slack app in the channel &amp; app token.</li> <li>Creating a Slack app \u2197\ufe0f</li> <li>Getting your app token \u2197\ufe0f</li> </ul>"},{"location":"nav/guide/config/alerts/slack.html#slack-module-config-variables-cli-commands","title":"Slack module config variables &amp; CLI commands","text":"<ul> <li><code>SLACK_TOKEN</code>: your Slack bot token (e.g. <code>xxxx-123456789101-12345678910-XXXXXXXXXXXXXXXXXXXXXXX</code>)</li> <li><code>SLACK_CHANNEL</code>: your Slack channel (e.g. your_channel_name)</li> </ul> <p>All Slack configs are currently environment variables, you can set them up using the sample code below:</p> <pre><code>export SLACK_TOKEN=xxxx-123456789101-12345678910-XXXXXXXXXXXXXXXXXXXXXXX\nexport SLACK_CHANNEL=your_channel_name\n</code></pre> <p>To alert to Slack, use the following:</p> <pre><code>diqu alert --to slack\n</code></pre>"},{"location":"nav/guide/config/alerts/slack.html#slack-message-body","title":"Slack message body","text":"<p>Our default Slack message consists of:</p> <ul> <li>Thread's header + timestamp</li> <li>A quick summary: <code>errors</code>, <code>warnings</code>, <code>passes</code>, and <code>deprecations</code> count.</li> <li>Top 3 issues:</li> <li>If you have previously defined <code>Priority</code> field in your custom Query, these are the 3 issues with the highest priority.</li> <li>If not, it's \ud83c\udf1frandom \ud83c\udf1f</li> </ul>"},{"location":"nav/guide/config/alerts/slack.html#sample-slack-message","title":"Sample Slack message","text":"<p> Summary on 2023-11-10 05:47:42.571000:</p> <ul> <li> 3 error(s)</li> <li> 3 warning(s)</li> <li> 2 pass(es)</li> <li> 0 deprecation(s)</li> </ul> <p> Top 3 Issues:</p> <ul> <li>[1] :large_yellow_circle: | Warning in test: accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8 [dq-tools]</li> <li>[2] :large_yellow_circle: | Warning in test: accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8 [dq-tools]</li> <li>[3] :large_yellow_circle: | Warning in test: accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8 [dq-tools]</li> </ul> <p> </p>"},{"location":"nav/guide/config/packages/custom_query.html","title":"Configuration for Custom query","text":"<p>If you're not using dq-tools package or even dbt, no problem, we're supporting a custom query directly to your data table/view.</p> <p>The steps are as follows:</p>"},{"location":"nav/guide/config/packages/custom_query.html#1-prepare-sql-script","title":"1. Prepare SQL script","text":"<p>Assuming we have a custom script named <code>issues.sql</code> which is located in the current directory.</p> <p>The script has to provide the expected columns required for all modules below:</p> Field Description <code>test_id</code> The unique identifier of the test. <code>test_status</code> Status of the test: 'pass', 'warn', 'fail', 'deprecate'. Example: <code>accepted_values_my_first_dbt_model_id__False__1__2.ee252c12b8</code> <code>test_title</code> Test's title to be shown in your module (e.g. in the Jira module, <code>test_title</code> is used as the issue's summary: <code>\ud83d\udfe1 | Warning in test: test_id [dq-tools]</code>). <code>check_timestamp</code> Test execution timestamp. <code>no_of_records_scanned</code> Number of rows scanned. <code>no_of_records_failed</code> Number of rows that did not pass the test. <code>failed_rate</code> Percentage of <code>no_of_records_failed / nullif(no_of_records_scanned, 0) as failed_rate</code>. <code>tag_1</code> Your 1<sup>st</sup> test tag (e.g. 'accepted_value'). <code>tag_2</code> Your 2<sup>nd</sup> test tag (e.g. <code>Accuracy</code>). <code>prev_statuses</code> An array of previous statuses (e.g <code>array_agg(test_status_emoji) within group (order by check_timestamp desc) as prev_statuses</code>). <code>prev_check_timestamps</code> An array of previous execution times of this test (e.g <code>array_agg(check_timestamp) within group (order by check_timestamp desc) as prev_check_timestamps</code>). <code>prev_no_of_records_scanned</code> An array of previous row scanned (e.g <code>array_agg(no_of_records_scanned) within group (order by check_timestamp desc) as prev_no_of_records_scanned</code>). <code>prev_no_of_records_failed</code> An array of previous row failed (e.g <code>array_agg(no_of_records_failed) within group (order by check_timestamp desc) as prev_no_of_records_failed</code>). <code>priority</code> Your priority level for each test. This field will be used for ordering the issues list in all modules. It is recommended to use numbers to simplify the process. <p>Let's build your <code>SELECT</code> query:</p> <pre><code>-- issue.sql\n\nselect  'your_value' as test_id,\n        'your_value' as test_status,\n        'your_value' as test_title,\n        'your_value' as check_timestamp,\n        'your_value' as no_of_records_scanned,\n        'your_value' as no_of_records_failed,\n        'your_value' as failed_rate,\n        'your_value' as tag_1,\n        'your_value' as tag_2,\n        'your_value' as prev_statuses,\n        'your_value' as prev_check_timestamps,\n        'your_value' as prev_no_of_records_scanned,\n        'your_value' as prev_no_of_records_failed,\n        'your_value' as priority,\n\nfrom    your_table\n</code></pre>"},{"location":"nav/guide/config/packages/custom_query.html#2-alerting","title":"2. Alerting","text":""},{"location":"nav/guide/config/packages/custom_query.html#setting-up-env-vars","title":"Setting up env vars","text":"<p>Set up Query variables: Query Variables Config</p> <p>Set up Alert Module variables:</p> <ul> <li>JIRA Configuration</li> <li>SLACK Configuration</li> </ul>"},{"location":"nav/guide/config/packages/custom_query.html#executing-alert-actions","title":"Executing alert actions","text":"<pre><code># prepare the env vars first\n...\n# run alerting\ndiqu alert --query-file issue.sql\n</code></pre>"},{"location":"nav/guide/config/packages/dq-tools.html","title":"Configuration for <code>dq-tools</code> dbt package","text":"<p>These are the essential steps to start alerting the Issues based on the test results which are captured by  package in a dbt project.</p>"},{"location":"nav/guide/config/packages/dq-tools.html#1-install-dq-tools-package","title":"1. Install <code>dq-tools</code> package","text":"<p>dbt version required: &gt;=1.6.0</p> <p>Include the following in your packages.yml file:</p> <pre><code>packages:\n  - package: infinitelambda/dq_tools\n    version: 1.4.2\n</code></pre> <p>Run <code>dbt deps</code> to install the package.</p> <p>\ud83d\udcd6 For more information on using packages in your dbt project, check out the dbt Documentation.</p>"},{"location":"nav/guide/config/packages/dq-tools.html#2-configure-the-log-table-the-hook","title":"2. Configure the log table &amp; the hook","text":"<p>The log table contains all the test results produced by dbt Jobs and can be configured by specifying the database or/and the schema. By default, this info will be getting from the dbt <code>profiles.yml</code>. The hook is to save the test result if any.</p> <p>In <code>dbt_project.yml</code> file:</p> <pre><code>vars:\n  dbt_dq_tool_schema: AUDIT\n\non-run-end:\n  - '{{ dq_tools.store_test_results(results) }}'\n</code></pre>"},{"location":"nav/guide/config/packages/dq-tools.html#3-build-your-models","title":"3. Build your models","text":"<p>In <code>dq-tools</code>, we can decide to save/not to save the test results using the <code>dq_tools_enable_store_test_results</code> variable. By default, it is <code>False</code>, therefore let's enable it to have data flowed in.</p> <pre><code># init the dq-tools' models\ndbt run -s dq_tools\n# build your dbt models with saving the test results\ndbt build --vars '{dq_tools_enable_store_test_results: true}'\n</code></pre>"},{"location":"nav/guide/config/packages/dq-tools.html#4-alerting","title":"4. Alerting","text":""},{"location":"nav/guide/config/packages/dq-tools.html#setting-up-env-vars","title":"Setting up env vars","text":"<p>Set up Query variables: Query Variables Config</p> <p>Set up Alert Module variables:</p> <ul> <li>JIRA Configuration</li> <li>SLACK Configuration</li> </ul>"},{"location":"nav/guide/config/packages/dq-tools.html#executing-alert-actions","title":"Executing alert actions","text":"<pre><code># prepare the env vars first\n...\n# run alerting\ndiqu alert --query-schema AUDIT\n</code></pre> <p><code>--query-schema</code> option is required here because we previously configured the <code>dbt_dq_tool_schema</code> variable</p>"},{"location":"nav/guide/config/packages/dq-tools.html#5-supported-dq-tools-metadata","title":"5. Supported dq-tools metadata","text":"<ul> <li>Latest &amp; historical tests' statuses, timestamps, row-failed counts, row-scanned counts, and failed rate.</li> <li><code>deprecated</code> status for tests that are not executed and recorded in x days.</li> <li>Tests labels (dq_issue_type, kpi_category)</li> </ul>"},{"location":"nav/guide/config/packages/query_variables.html","title":"Configuration for Query Variables","text":"<p>Currently, Query variables are only defined in the query for <code>dq-tools</code>. They are not compulsory if you are using CSV as the Source Module, or Custom Query as the Package Module.</p> <p>However, it is highly recommended to define query variables for flexibility in controlling when &amp; how your alerts would be fired.</p> <p>For example, with the built-in <code>dq-tools</code> Package Module, we are using the following 2 environment variables:</p> <ul> <li><code>ISSUE_DEPRECATED_WINDOW_IN_DAYS</code> (default = 3 days): Identify when an issue is marked as deprecated by comparing the last executed timestamp of each issue with the current <code>sysdate()</code></li> <li><code>ISSUE_UPDATE_WINDOW_IN_DAYS</code> (default = 14 days): Identify the update window to limit the number of rows returned by our query. In other words, in the default case of 14, only the tests that were executed in the last 14 days from the current <code>sysdate()</code> are returned.</li> </ul> <p>See <code>dq_tools__get_test_results.sql</code> in the code base for details.</p> <p>To configure these environment variables, use the following:</p> <pre><code>export ISSUE_DEPRECATED_WINDOW_IN_DAYS=3\nexport ISSUE_UPDATE_WINDOW_IN_DAYS=14\n</code></pre>"},{"location":"nav/guide/config/sources/custom_csv.html","title":"Configuration for Other connection via CSV file","text":"<p>Currently, the only supported connection is Snowflake, we'll see more added in the near future.</p> <p>In the meantime, using a CSV file is a good alternative.</p>"},{"location":"nav/guide/config/sources/custom_csv.html#1-configure-the-dbt-profile","title":"1. Configure the dbt profile","text":"<p>Let's create a new target for CSV in the dbt <code>profiles.yml</code> file:</p> <pre><code>ci:\n  target: dev\n  outputs:\n    dev:\n      type: csv\n      dir: ./.cache\n      # dir: \"{{ env_var('DQT_CSV_DIR') }}\"\n</code></pre>"},{"location":"nav/guide/config/sources/custom_csv.html#2-generate-csv-file","title":"2. Generate CSV file","text":"<p>No matter what CLI tool you use, it is required to query and save data into a <code>.csv</code> file in <code>.cache</code> folder.</p> <p>The default file name is <code>csv__data.csv</code>.</p> <p>The file's schema must be defined with the same column names as specified in Custom Query Config</p>"},{"location":"nav/guide/config/sources/custom_csv.html#3-alerting","title":"3. Alerting","text":"<pre><code>diqu alert --target dev \\\n  --query-dir ./.cache --query_file csv__data.csv\n  --package csv\n</code></pre>"},{"location":"nav/guide/config/sources/snowflake.html","title":"Configuration for Snowflake connection","text":"<p>In order to use Snowflake as the data source, we need to get the additional dependencies after installing <code>diqu</code>:</p> <pre><code>pip install \"snowflake-connector-python[pandas]\"\npip install \"snowflake-connector-python[secure-local-storage]\"\n</code></pre> <p><code>diqu</code> will try to reuse dbt profile configuration with supporting 3 authentication methods:</p>"},{"location":"nav/guide/config/sources/snowflake.html#user-password-authentication","title":"User / Password authentication","text":"<p>Snowflake can be configured using basic user/password authentication as shown below.</p> <pre><code># ~/.dbt/profiles.yml\ndiqu:\n  target: dev\n  outputs:\n    dev:\n      type: snowflake\n      account: [account id]\n\n      # User/password auth\n      user: [username]\n      password: [password]\n\n      role: [user role]\n      database: [database name]\n      warehouse: [warehouse name]\n      schema: [dbt schema]\n</code></pre>"},{"location":"nav/guide/config/sources/snowflake.html#key-pair-authentication","title":"Key Pair Authentication","text":"<p>To use key pair authentication, omit a <code>password</code> and instead provide a <code>private_key_path</code> and, optionally, a <code>private_key_passphrase</code> in your target.</p> <p>Also you have the option to use a <code>private_key</code> string instead of a <code>private_key_path</code>. The <code>private_key</code> string should be in either Base64-encoded DER format, representing the key bytes, or a plain-text PEM format. Refer to Snowflake documentation for more info on how they generate the key.</p> <pre><code># ~/.dbt/profiles.yml\ndiqu:\n  target: dev\n  outputs:\n    dev:\n      type: snowflake\n      account: [account id]\n\n      # Keypair config\n      private_key_path: [path/to/private.key]\n      # OR:\n      # private_key: [value is Base64-encoded DER format (key bytes), or a plain-text PEM format]\n      private_key_passphrase: [passphrase for the private key, if key is encrypted]\n\n      role: [user role]\n      database: [database name]\n      warehouse: [warehouse name]\n      schema: [dbt schema]\n</code></pre>"},{"location":"nav/guide/config/sources/snowflake.html#sso-authentication","title":"SSO Authentication","text":"<p>To use SSO authentication for Snowflake, omit a <code>password</code> and instead supply an <code>authenticator</code> config to your target. <code>authenticator</code> should be 'externalbrowser' for now.</p> <pre><code># ~/.dbt/profiles.yml\ndiqu:\n  target: dev\n  outputs:\n    dev:\n      type: snowflake\n      account: [account id]\n\n      # User\n      user: [username]\n      # SSO config\n      authenticator: externalbrowser\n\n      role: [user role]\n      database: [database name]\n      warehouse: [warehouse name]\n      schema: [dbt schema]\n</code></pre>"}]}